{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#crisp-compliant-ros2-controllers-for-learning-based-manipulation-policies","title":"CRISP - Compliant ROS2 Controllers for Learning-Based Manipulation Policies","text":"<p>Authors: Daniel San Jose Pro, Oliver Hausd\u00f6rfer, Ralf R\u00f6mer, Maximilian D\u00f6sch, Martin Schuck and Angela Sch\u00f6llig.</p> <p>A collection of real-time, C++ controllers for compliant torque-based control for manipulators compatible with <code>ros2_control</code>. Developed for deploying high-level learning-based policies (VLA, Diffusion, ...) and teleoperation on your manipulator. It is compatible with any manipulator offering and effort interface.</p> <p>If you use this work, please cite it using the bibtex below.</p> <p>Check the controllers (CRISP controllers)  , robot demos (CRISP controllers demos) , a simple python interface (CRISP_PY) , and a Gymnasium wrapper (CRISP_GYM)  for real-world experiments.</p> Robot teleoperated using a Follower-Leader system in CRISP_GYM  Diffusion Policy trained and deployed from the same demonstrations Robot following a moving target, while base joint follows a sine curve Simulated kinova robot with continous joints and nullspace control Simulated iiwa robot Real robot following a target and being disturbed (contact) + null space control demonstration Demonstration using a cartesian controller teleoperated using Vicon tracking system (Speed x4) Teleoperation setup with activated force-torque feedback"},{"location":"#why","title":"Why?","text":"<p>Learning-based controllers, such as diffusion policies, deep reinforcement learning, and vision-action-models in general, typically output low-frequency or sporadic target poses, necessitating a low-level controller to track these references smoothly, especially in contact-rich environments. While <code>ROS2</code> frameworks like <code>MoveIt</code> offer comprehensive motion planning capabilities, they are often unnecessarily complex for tasks requiring simple, real-time pose or joint servoing.</p> <p>We present a set of lightweight, torque-based Cartesian and joint-space controllers implemented in C++ for <code>ros2_control</code>, compatible with any robot exposing an effort interface\u2014a common standard among modern manipulators. Our controllers incorporate friction compensation, joint limit avoidance, and error clipping, and have been validated on the Franka Robotics FR3 on hardware, and on various platforms in simulation.</p> <p>Designed for fast integration and real-time control, our implementation lowers the barrier to deploying learning-based algorithms on <code>ROS2</code>-compatible platforms.</p> <p>Why the name \"CRISP\"? \"CRISP\" reflects our design philosophy behind the package: a concise, to-the-point implementation for easy deployment and integration in other software stacks.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>\ud83d\udc0d Python interface to move your ROS2 robot around without having to think about topics, spinning, and more ROS2 concepts but without loosing the powerful ROS2 API. Check CRISP_PY for more information and examples.</li> <li>\ud83d\udd01 Gymnasium environment with utilities to deploy learning-based policies and record trajectories in LeRobotFormat. Check CRISP_GYM.</li> <li>\u2753 Demos showcasing how to use the controller with FR3 of Franka Emika in single and bimanual setup. Check the crisp_controller_demos.</li> <li>\u2699\ufe0f Dynamically and highly parametrizable: powered by the <code>generate_parameter_library</code> you can modify stiffness and more during operation.  </li> <li>\ud83e\udd16 Operational Space Controller as well as Cartesian Impedance Controller for torque-based control.  </li> <li>\ud83d\udeab No MoveIt or complicated path-planning, just a simple C++ <code>ros2_controller</code>. Ready to use.  </li> </ul>"},{"location":"#citing","title":"Citing","text":"<pre><code>@inproceeding{\n   TODO\n}\n</code></pre>"},{"location":"getting_started/","title":"Getting started","text":"<p>Here is an overview of the CRISP framework (please check our paper for details).</p> <p> </p> <ul> <li> 1. The first part is the setup for the low-level crisp_controllers.</li> <li> 2. Then, you will try moving the robot using CRISP_PY python interface.</li> <li> 3. Then, you can optionally include additional cameras and other sensors in your setup. </li> <li> 4. Finally, you can set up CRISP_GYM - the Gymnasium interface - and start policy deployment or teleoperation.</li> </ul>"},{"location":"getting_started/#1-getting-the-low-level-c-crisp-controller-ready","title":"1. Getting the low-level C++ CRISP controller ready","text":"<p>The computer running the CRISP controller needs a real-time patch for the controller to run smoothly and safely. You can check out the Franka Robotics guide on how to set up a RT-patch. On newer Ubuntu versions, you can use Ubuntu Pro for an easy setup.</p> <p>Then, check if your robot is already included in one of our demos, check how to run a demo from our demos repository. You can then follow the instructions there to start your robot(s) using a Docker container. Some of them offer the possibility to run the demos with simulated robots to test the setup.</p> <p>If your robot is not included in the demos that is not problem. Check out How to set up a robot that is not available in the demos. Once you get the controllers running, feel free to open a pull request on our repo to add it to the demos! We highly appreciate that!</p>"},{"location":"getting_started/#2-use-the-python-interface-crisp_py-to-control-the-robot","title":"2.  Use the python interface CRISP_PY to control the robot","text":""},{"location":"getting_started/#installation","title":"Installation","text":"<p>Note</p> <p>If you want to use the gymnasium interface, CRISP_PY will be autonmatically installed in the gym. You can therefore check the installation of CRISP_GYM directly. However, this section still gives you an idea on how to use CRISP_PY with your robot. We do not recommend to skip it.</p> <p>To use <code>CRISP_PY</code>, we recommend using pixi as a package manager, a modern conda-like package manager. It can be used in combination with robostack to easily install ROS2 in any machine. There are a few ways to get you started:</p> <p>... install from source:</p> <pre><code>git clone https://github.com/utiasDSL/crisp_py\ncd crisp_py\npixi install\npixi shell -e humble\npython -c \"import crisp_py\"  # (1)!\n</code></pre> <ol> <li>This should not log anything if everything is fine</li> </ol> <p>... use in your already existing pixi project:</p> <p>To use <code>CRISP_PY</code> in an already existing pixi project, you need to make sure that <code>ROS2</code> is available. Check the pixi.toml of <code>CRISP_PY</code> to see how this looks like. Then you can add <code>CRISP_PY</code> as a pypi package: <pre><code>pixi add --pypi crisp-py\n</code></pre> or <pre><code>uv add crisp-py\n</code></pre> or <pre><code>pip install crisp-py\n</code></pre> Double-check that everything is working by running:</p> <pre><code>python -c \"import crisp_py\"  # (1)!\n</code></pre> <ol> <li>This should not log anything if everything is fine</li> </ol> <p>Now you can try to control the robot! Check out the examples for inspiration.</p>"},{"location":"getting_started/#try-it-out-with-the-robot","title":"Try it out with the robot","text":"<p>Make sure that the demo container is running in the background, as we will need it to access the robot. From now on, you can instantiate <code>Robot</code> objects to control the robot.</p> Example robot usage: <pre><code>from crisp_py.robot import Robot\nfrom crisp_py.robot_config import RobotConfig\n\nrobot_config = RobotConfig(...)\nrobot = Robot(namespace=\"...\", config=robot_config)  # (1)!\nrobot.wait_until_ready()  # (2)!\n\nprint(robot.end_effector_pose)\n\n\nrobot.controller_switcher_client.switch_controller(\n    \"cartesian_impedance_controller\",  # (4)!\n)  \nx, y, z = robot.end_effector_pose.position\nrobot.set_target(position=[x, y, z-0.1])  # (3)!\n\nrobot.shutdown()\n</code></pre> <ol> <li>This will get information from the robot asynchronously</li> <li>Make sure that we get information from the robot before trying to set targets or reading the pose of the robot.</li> <li>Set target 10 cm downwards. Careful not to send poses that are too far away from the current one!</li> <li>This will request the controller manager to activate the cartesian impedance controller. You can use it with other controllers like the operational space controller!</li> </ol>"},{"location":"getting_started/#3-adding-cameras-grippers-and-further-sensors-to-crisp_py","title":"3. Adding cameras, grippers, and further sensors to CRISP_PY","text":""},{"location":"getting_started/#cameras","title":"Cameras","text":"<p>To add a camera, you will need to run it in a separate container as well. The cameras that we tested are:</p> <ul> <li>Real Sense which gives amazing ROS2 support,</li> <li>and Orbbec.</li> </ul> <p>But any camera with camera_ros should work. Check the demos to see some examples with cameras</p> Example camera usage: <pre><code>import cv2\nfrom crisp_py.camera import Camera, CameraConfig\n\ncamera_config = CameraConfig(\n    camera_name=\"primary\",\n    resolution=(256, 256),  # (1)!\n    camera_color_image_topic=\"camera_name/color/image_raw\",  # (2)!\n    camera_color_info_topic=\"camera_name/color/camera_info\",\n)\n\ncamera = Camera(config=camera_config)  # (3)!\ncamera.wait_until_ready() # (4)!\n\ncv2.imshow(\"Camera Image\", camera.current_image)  # (5)!\ncv2.waitKey(0)\n</code></pre> <ol> <li>You can define a custom resolution, independently of the resolution of the published image.</li> <li>Set here the topic of your custom camera name</li> <li>You can also pass <code>namespace=\"...\"</code> to give the camera a namespace. This is required for a bimanual setup.</li> <li>Make sure that we received an image. This will fail with a timeout if the topic is wrong or the camera is not publishing.</li> <li>This will show you the latest received image!</li> </ol>"},{"location":"getting_started/#grippers","title":"Grippers","text":"<p>For gripper control, you need to make sure that a ROS2 node is running that accepts commands through a topic and publishes the state of the gripper. To use a:</p> <ul> <li>Franka Hand, you just need to start the demo. An adapter is already running to allow you to control the gripper this way,</li> <li>Dynamixel motor to control a gripper, we used the well-maintained dynamixel_hardware_interface with a position controller for the gripper.</li> </ul> Example gripper usage: <p>You can use the gripper in <code>crisp_py</code> with: <pre><code>from crisp_py.gripper import Gripper, GripperConfig\n\n# config = GripperConfig.from_yaml(path=\"...\")  (1)\nconfig = GripperConfig(\n    min_value=0.0,\n    max_value=1.0,\n    command_topic=\"gripper_position_controller/commands\",\n    joint_state_topic=\"joint_states\",\n)  # (2)!\ngripper = Gripper(gripper_config=config)  # (3)!\ngripper.wait_until_ready()  # (4)!\n\nprint(gripper.value)\n\ngripper.open()\n# gripper.close()\n# gripper.set_target(0.5)\n</code></pre></p> <ol> <li>You can load the configs from a yaml file. If you calibrate the gripper manually (check the crisp_py docs for more information) you can select this way your custom calibration file.</li> <li>Set the range of allowed commands (min stands for fully closed, max to fully open) and the topics for the gripper. You can check the topics using <code>ros2 topic list</code></li> <li>You can also pass <code>namespace=\"...\"</code> to give the gripper a namespace. This is required for a bimanual setup.</li> <li>Make sure that we received a gripper value. This will fail with a timeout if the topic is wrong or the gripper is not publishing.</li> </ol>"},{"location":"getting_started/#sensors","title":"Sensors","text":"<p>You can add further sensors (Force Torque Sensor, Tactile Sensor...) by adding a custom <code>Sensor</code> that subscribes to a topic. Check the examples for more information.</p>"},{"location":"getting_started/#4-getting-started-with-crisp_gym","title":"4. Getting started with CRISP_GYM","text":"<p>Similar to <code>CRISP_PY</code>, we recommend using <code>pixi</code> to install <code>CRISP_GYM</code>.</p> <p><pre><code>git clone https://github.com/utiasDSL/crisp_gym\ncd crisp_gym\n</code></pre> Now, you should set a few things before installing everything. Create a file <code>scripts/set_env.sh</code> which will be sourced every time that you run a command in your environment. The script will not be tracked by git. In this script you need to add a environment variables:</p> <ul> <li><code>ROS_DOMAIN_ID</code>: which is used to define nodes that should be able to see each other. In our demos they are set to 100 as default.</li> <li><code>CRISP_CONFIG_PATH</code>: which should be the path to a config folder similar to config path of CRISP_PY. The easiest way to do this is to clone CRISP_PY somewhere and set this environment variable to point to it.</li> </ul> scripts/set_env.sh<pre><code>export ROS_DOMAIN_ID=100\nexport CRISP_CONFIG_PATH=/path/to/crisp_py/config  # (1)!\n</code></pre> <ol> <li>Modify this!</li> </ol> <p>If you want to work in a multi-machine setup (e.g. policy runs in a different machine as controllers), then check how to setup multi-machine in ROS2.</p> <pre><code>source scripts/configure.sh  # (1)!\npixi install\npixi shell -e humble-lerobot\npython -c \"import crisp_gym\"\n</code></pre> <ol> <li>This will set some environment variable pre-installation as well as checking that you defined the previous script properly.</li> </ol> <p>If the previous steps worked, then you are good to go.</p>"},{"location":"getting_started/#teleoperation-record-data-in-lerobotformat","title":"Teleoperation: Record data in LeRobotFormat","text":"<p>You can record data in <code>LeRobotFormat</code> to train a policy directly in LeRobot. You will need to use teleoperation to record data and we highly recommend using a leader-follower setup to generate episodes. </p>"},{"location":"getting_started/#leader-follower","title":"Leader-follower","text":"<p>The leader can be controlled by a human operator and the follower will mimic its motion. Checkout <code>scripts/leader_follower_teleop.py</code> to get an idea on how the code works. For your specific setup you need to:</p> <ul> <li>Define your own <code>TeleopRobotConfig</code>, check <code>teleop_robot_config.py</code>.</li> <li>Define your own <code>ManipulatorEnvConfig</code>, check <code>manipulator_env_config.py</code>.</li> </ul> <p>Then, to record data use: <pre><code>pixi run -e humble-lerobot python scripts/record_lerobot_format_leader_follower.py \\\n   --repo-id &lt;your_account&gt;/&lt;repo_name&gt; # (1)!\n</code></pre></p> <ol> <li>Add <code>--help</code> to check other parameters to pass to the record function.</li> </ol> <p>The script is interactive. It will first ask to choose the desired configuration files for the recording and then allow you to record episodes interactively. There are two recording methods currently available:</p> <ul> <li><code>keyboard</code> (default): It allows you to record episodes using the keyboard with the keys <ul> <li>r(ecord start/stop) an episode,</li> <li>d(elete episode) after recording a failed episode,</li> <li>s(ave episode) after recording a succesful episode,</li> <li>q(uit) after finishing.</li> </ul> </li> <li> <p><code>ros</code>: It uses the topic <code>recording_state</code> to catch <code>String</code> ROS2 messages to follow the same recording workflow as the keyboard.      With this you can implement custom recording devices to control the recording workflow</p> Using the FR3 pilot buttons of Franka Robotics as a recording device <p>In our lab, we use the buttons of the leader robot as a recording device with the franka-buttons repository. The following script uses the circle, cross, check and up buttons as a record, delete, save and quit commands respectively: <pre><code>TODO\n</code></pre></p> </li> </ul> <p>After this, you can visualize the episodes with rerun visualizer and LeRobot utils: <pre><code>pixi run -e lerobot python -m lerobot.scripts.visualize_dataset \\\n        --repo-id &lt;your_account&gt;/&lt;repo_name&gt; \\\n        --episode-index 0\n</code></pre></p> <p>Warning</p> <p>LeRobot is subjected to rapid changes. This command might change in future versions.</p>"},{"location":"getting_started/#other-teleop-setups","title":"Other teleop setups","text":"<p>You can add further teleop options to <code>teleop/</code> and create  a similar record script as <code>scripts/record_lerobot_format_leader_follower.py</code></p>"},{"location":"getting_started/#train-a-policy","title":"Train a policy","text":"<p>You can use LeRobot train scripts to train a policy simply by running: <pre><code>pixi run -e lerobot python -m lerobot.scripts.train \\\n          --dataset.repo_id=&lt;your_account&gt;/&lt;repo_name&gt; \\\n          --policy.type=diffusion \\\n          --policy.push_to_hub=false\n</code></pre></p> <p>Warning</p> <p>LeRobot is subjected to rapid changes. This command might change in future versions.</p> <p>They provide the latest implementations of most VLA. Check LeRobot for more information.</p>"},{"location":"getting_started/#deploy-policy","title":"Deploy policy","text":"<p>After training with LeRobot, you can deploy the policy with: <pre><code>pixi run -e humble-lerobot python scripts/deploy_policy.py # (1)!\n</code></pre></p> <ol> <li>The script will interactively allow you to choose a model inside <code>outputs/train</code>. If you want to explicitly pass a path you can override it with <code>--path</code></li> </ol> <p>Warning</p> <p>LeRobot is subjected to rapid changes. This command might change in future versions.</p> <p>Good job, now you can evaluate your model!</p>"},{"location":"misc/calibrate_gripper/","title":"How to calibrate a gripper","text":""},{"location":"misc/calibrate_gripper/#how-to-calibrate-a-gripper","title":"How to calibrate a gripper","text":"<p>To grasp, make sure that you set the proper <code>min_value</code> and <code>max_value</code> in the config for the range in which the gripper joint moves. All joint values are normalized between 0 (closed) and 1 (open) and the joint values vary from <code>min_value</code> and <code>max_value</code>.</p> <p>To calibrate a gripper, use the script provided in <code>crisp_py</code>: <pre><code>python scripts/gripper_manual_calibration.py --help\n</code></pre> The script will guide you in calibration procedure: </p> <p>After this, control the gripper as follows: <pre><code>from crisp_py.gripper import Gripper, GripperConfig\n\ngripper_config = GripperConfig.from_yaml(\"path/to/yaml\")\n# or gripper_config = GripperConfig(min_value=x.x, max_value=x.x)\n\ngripper = Gripper(config=gripper_config)\ngripper.open()  # equivalent to gripper.set_target(1.0)\ngripper.close()  # equivalent to gripper.set_target(0.0)\ngripper.set_target(0.5)\ngripper.shutdown()\n</code></pre></p>"},{"location":"misc/controllers/","title":"Available controllers","text":""},{"location":"misc/controllers/#default-controllers","title":"Default controllers","text":"<p>In CRISP_PY you can find some of the default configurations that we used with the FR3 of Franka Robotics. These configurations are:</p> <ul> <li><code>default_cartesian_impedance.yaml</code>: A simple config for a Cartesian Impedance (CI) Controller. This is our go-to controller, since it offers nice contact behavior and is the perfect balance between compliance and precision.</li> <li><code>default_operational_space_controller.yaml</code>: A simple config for Operational Space Controller (OSC). Is a slightly stiffer controller. The contact behavior might not be as nice as for CI.</li> <li><code>clipped_cartesian_impedance.yaml</code>: A simple config of a highly clipped error CI (CI-clipped). This offers a highly stiff controller but at the same time safe since the error is highly clipped. Useful for precise manipulation.</li> </ul> <p>Experiments using these sets of parameters can be found in our paper.</p>"},{"location":"misc/demos/","title":"Demos","text":""},{"location":"misc/demos/#available-demos","title":"Available demos","text":"<p>For now, these are the available demos in this repository. New demos are welcome, in particular if tested with real hardware. Some other manipulators that could be added to this list is the Open Manipulator or other dual setups.</p> Robots Franka Robotics FR3 FR Dual FR3 IIWA 14 Kinova Gen3 MuJoCo simulated Hardware \u2705 \u2705 \u2705 \u2705 Real Hardware \u2705 \u2705 \u2754<sup>1</sup> \u2754<sup>1</sup> <p>We also have some examples with cameras.</p> Robots Real Sense Orbecc Any webcam Camera demo \u2705 \u2754<sup>2</sup> \u2754<sup>2</sup>"},{"location":"misc/demos/#running-a-demo","title":"Running a demo","text":"<ol> <li>(TEMPORARY) Clone the crisp controllers to the repo (later it will be part of the Dockerfile) <pre><code>git clone git@github.com:utiasDSL/crisp_controllers_demos.git crisp_controllers_demos\ncd crisp_controllers_demos\ngit clone git@github.com:utiasDSL/crisp_controllers.git crisp_controllers\n</code></pre></li> </ol> <p>Warning</p> <p>Do NOT use Docker Desktop. Just go for the normal Docker CLI.</p> <ol> <li>Build and start the provided container. <pre><code>docker compose build\n</code></pre></li> <li> <p>Start your robot: <pre><code>docker compose up launch_iiwa\n</code></pre> or <pre><code>LEFT_ROBOT_IP=172.16.1.2 \\\nRIGHT_ROBOT_IP=172.16.0.2 \\\nFRANKA_FAKE_HARDWARE=true \\\ndocker compose up launch_dual_franka\n</code></pre> or <pre><code>ROBOT_IP=172.16.0.2 \\\nFRANKA_FAKE_HARDWARE=true\\\ndocker compose up launch_franka\n</code></pre> or <pre><code>docker compose up launch_kinova\n</code></pre></p> </li> <li> <p>Now you can publish to <code>/target_joint</code>, <code>/target_wrench</code> or <code>/target_pose</code>! Check crisp_py examples to see how to easily use it.</p> </li> </ol> <p>Warning</p> <p>If you work in different machines (using crisp_py or others) you might want to consider using a different RMW. Check how to multi-machine setup. To use a different middleware just pass an extra environment variable: <pre><code>RMW=&lt;zenoh|cyclone&gt; docker compose up ...\n</code></pre></p> <p>For the cameras, you can run: <pre><code>docker compose up launch_realsense\n</code></pre></p> <p>Check the <code>docker-compose.yaml</code> to see how to define your own services.</p>"},{"location":"misc/demos/#troubleshooting","title":"Troubleshooting","text":"Rviz does not open when launch the robots. Why? <p>Simply run <code>xhost +</code> on a terminal to enable any host to use the X. You need this because we are running the demos in a container.</p> When executing <code>ros2 topic list</code> in a different terminal, I can not see any topics. However, the container is running. Why? <p>Probably you are using a different <code>ROS_DOMAIN_ID</code>. The default now is set to 100 but you can change it when running the container. To change it in your shell run <code>export ROS_DOMAIN_ID=100 &amp;&amp; ros2 daemon stop &amp;&amp; ros2 daemon start</code>.</p> How are the manipulors being simulated? <p>We implemeted a simple <code>MujocoHardwareInterface</code> to simulate the robots. This code is heavily inspired by the simulator in cartesian_controllers, but probably better alternatives to use mujoco as a backend simulation would be mujoco_ros2_control. One could also use gazebo.  The mujoco files come from the mujoco menagerie and have been slightly modified to use torque based actuators + we added some friction to the joints (to increase realism).</p> <ol> <li> <p>Untested, but effort interface available.\u00a0\u21a9\u21a9</p> </li> <li> <p>TODO, still not available in the demos\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"misc/diagnostics/","title":"ROS2 Diagnostics","text":"<p>ToDo</p>"},{"location":"misc/multi_machine_setup/","title":"Multi-machine setup","text":"<p>To setup multiple machines, we recommend using a different RMW.  In our demos we provide the option to use Zenoh or CycloneDDS. The setup with CycloneDDS uses multicast and might be a problem for your university/enterprise network. You might want to try Zenoh in that case, which uses a router for node discovery.</p>"},{"location":"misc/multi_machine_setup/#using-zenoh-for-multi-machine-setups","title":"Using Zenoh for multi-machine setups","text":"<p>Zenoh /zeno/ is a pub/sub/query protocol unifying data in motion, data at rest and computations - from Zenoh's website.</p> <p>rmw_zenoh is a ROS middleware to use Zenoh as a the pub/sub communication instead of DDS developed by Intrinsic. To learn more about Zenoh, check their website and learn about the Zenoh middleware in their repository.</p> <p>What's important for us to know is that a router is required for discovery similar to how roscore worked in ROS1. It can be configured with multicast and the avoid using the router but we will avoid a multicast setup since it might cause problems in some networks for example in universities.</p>"},{"location":"misc/multi_machine_setup/#in-the-host-machine-where-the-controllers-run","title":"In the host machine (where the controllers run)","text":"<p>In the machine running the controllers, make sure that you start one Zenoh router. In the demos repository, we provide a service to start the router: <pre><code>docker compose up launch_zenoh_router\n</code></pre></p> <p>This will start a Zenoh router, then all other nodes can be initialized. To use the demos with <code>zenoh</code> as a middleware, pass the following environment variable to the services: <pre><code>RMW=zenoh docker compose up ...\n</code></pre> The setup in the host machine is done!</p>"},{"location":"misc/multi_machine_setup/#in-the-remote-machine-where-the-learning-based-policy-runs","title":"In the remote machine (where the learning-based policy runs)","text":"<p>In this part, we assume that you already installed the CRISP_PY or CRISP_GYM.</p> <ol> <li> <p>Make sure that the Zenoh RMW is installed <code>ros-$ROS_DISTRO-rmw-zenoh-cpp</code>. If you use the <code>pixi.toml</code> provided      in this repo it should be the case.</p> </li> <li> <p>Now you can modify your<code>scripts/set_env.sh</code> to include further configuration lines:      scripts/set_env.sh<pre><code>export ROS_DOMAIN_ID=100  # (1)! \nexport CRISP_CONFIG_PATH=/path/to/crisp_py/config  # (1)!\n\nexport RMW_IMPLEMENTATION=rmw_zenoh_cpp\nexport ZENOH_CONFIG_OVERRIDE='mode=\"client\";\\\n  connect/endpoints=[\"tcp/YOUR_HOST_IP:7447\"]'  # (2)!\n\nros2 daemon stop &amp;&amp; ros2 daemon start  # (3)!\n</code></pre></p> <ol> <li>Check the getting started to see why we set this.</li> <li>TODO: modify this to use the IP address </li> <li> <p>The communication daemon needs to be restarted to account for the changes.</p> </li> <li> <p>Finally, check that everything is working.  Enter in the humble shell with <code>pixi shell -e humble</code> and if your robot is active, run <code>ros2 topic list</code> and you should see some topics listed!</p> </li> </ol> </li> </ol>"},{"location":"misc/multi_machine_setup/#using-cyclonedds-for-multi-machine-setups","title":"Using CycloneDDS for multi-machine setups","text":""},{"location":"misc/multi_machine_setup/#in-the-host-machine-where-controllers-run","title":"In the host machine (where controllers run)","text":"<p>To use the demos with <code>cyclone</code> as a middleware, pass the following environment variable to the services: <pre><code>RMW=cyclone ROS_NETWORK_INTERFACE=enpXXXXXX docker compose up ...  # (1)!\n</code></pre></p> <ol> <li>Modify this with your network interface: check <code>ip addr</code> on your shell. Otherwise it will just use <code>lo</code> as default.</li> </ol> <p>If you are using a custom robot, check the <code>setup_cyclone.sh</code> script to see how it is being configured.</p>"},{"location":"misc/multi_machine_setup/#in-the-remote-machine-where-the-learning-policy-runs","title":"In the remote machine (where the learning policy runs)","text":"<ol> <li> <p>Make sure that the Cyclone RMW is installed <code>ros-$ROS_DISTRO-rmw-cyclonedds-cpp</code>. If you use the <code>pixi.toml</code> provided     in this repo it should be the case.</p> </li> <li> <p>Now you can modify your<code>scripts/set_env.sh</code> to include further configuration lines:      scripts/set_env.sh<pre><code>export ROS_DOMAIN_ID=100  # (1)! \nexport CRISP_CONFIG_PATH=/path/to/crisp_py/config  # (1)!\n\nexport ROS_NETWORK_INTERFACE=enpXXXXXX  # (2)!\nexport RMW_IMPLEMENTATION=rmw_cyclonedds_cpp\nexport CYCLONEDDS_URI=file:///path/to/crisp_gym/scripts/cyclone_config.xml  # (3)!\n\nros2 daemon stop &amp;&amp; ros2 daemon start  # (4)!\n</code></pre></p> <ol> <li>Check the getting started to see why we set this.</li> <li>Modify this with your network interface: check <code>ip addr</code> on your shell.</li> <li>TODO: this file as well as the path need to be modified!</li> <li>The communication daemon needs to be restarted to account for the changes.</li> </ol> </li> <li> <p>Finally, check that everything is working.  Enter in the humble shell with <code>pixi shell -e humble</code> and if your robot is active, run <code>ros2 topic list</code> and you should see some topics listed!</p> </li> </ol>"},{"location":"misc/multi_machine_setup/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Make sure that the Zenoh versions are the same across all the machines!</li> <li>Run <code>env | grep RMW_IMPLEMENTATION</code>, if the variable is not set, you need to make sure that the script <code>scripts/set_env.sh</code> is being executed!</li> <li>Be sure that the name of the interface is correct!</li> </ul>"},{"location":"misc/multi_machine_setup/#references","title":"References","text":"<ul> <li>iRobot Middleware Config: https://iroboteducation.github.io/create3_docs/setup/xml-config/</li> <li> <p>MoveitPro customize DDS: https://docs.picknik.ai/how_to/configuration_tutorials/customize_dds_configuration/</p> </li> <li> <p>Cyclone Run-Time-Configuration: https://github.com/eclipse-cyclonedds/cyclonedds/tree/a10ced3c81cc009e7176912190f710331a4d6caf#run-time-configuration</p> </li> <li>StereoLabs improve performance: https://www.stereolabs.com/docs/ros2/dds_and_network_tuning#change-dds-middleware</li> <li> <p>Husarion DDS setup: https://husarion.com/tutorials/other-tutorials/husarnet-cyclone-dds/</p> </li> <li> <p>ROS2 Doctor: https://docs.ros.org/en/kilted/Tutorials/Beginner-Client-Libraries/Getting-Started-With-Ros2doctor.html</p> </li> </ul>"},{"location":"misc/new_robot_setup/","title":"Setting up a robot that is not available in the demos","text":"<p>For ROS2 users, adding our controllers to their stack should be straightforward as it works like any other ROS2 controller. For novice ROS2 users, we prepared a more detailed guide to make sure that you get your robot ready:</p> <ol> <li> <p>First make sure that your ROS2 drivers for the robot you want to use allow direct-torque control i.e. the effort command interface is available. Usually, you should be able to find it in the Github repository.  If this is the case, you are good to go.  Otherwise, you might need to use cartesian_controllers for position controlled robots.</p> </li> <li> <p>Install the ROS2 drivers on your computer.  We recommend to work in a devcontainer to avoid installing ROS2 directly in your machine. You can check the demos for inspiration.</p> </li> <li> <p>Add the controllers to your src folder where the ROS2 drivers for your robot have been installed:     <pre><code>cd ~/ros2_ws  # or wherever you ws is...\ngit clone https://github.com/utiasDSL/crisp_controllers.git src/crisp_controllers\nsource /opt/ros/$ROS_DISTRO/setup.sh\nsource /install/setup.sh\nrosdep update\nrosdep install -q --from-paths src --ignore-src -y  # (1)!\ncolcon build --packages-select crisp_controllers \ntouch src/crisp_controllers/COLCON_IGNORE  # (2)! \nsource /install/setup.sh  # (3)!\n</code></pre></p> <ol> <li>This line will make sure that all missing dependencies are installed</li> <li>By adding this file, the controller will not be built over and over</li> <li>Don't forget to source again to make sure that ROS2 can find the new package</li> </ol> </li> <li> <p>Now, you will need to add the controller to the config file of the controller_manager. Usually, you will find this config file in the bringup package where the launch files are located (called <code>&lt;robotname&gt;_bringup</code>) and are saved as <code>controllers.yaml</code>. Check out the FR3 config to get an idea how the config file looks like. For more information on the controllers, check the available controllers and broadcaster page.</p> How to add the configuration to the config file <pre><code>/**:\ncontroller_manager:\n    ros__parameters:\n    update_rate: 1000  # Hz\n\n    pose_broadcaster:\n        type: crisp_controllers/PoseBroadcaster\n\n    gravity_compensation:\n        type: crisp_controllers/CartesianImpedanceController\n\n    cartesian_impedance_controller:\n        type: crisp_controllers/CartesianImpedanceController\n\n    joint_impedance_controller:\n        type: crisp_controllers/CartesianImpedanceController\n\n    # more controllers...\n/**:\npose_broadcaster:\n    ros__parameters:\n    joints:\n        - &lt;TODO&gt;\n\n    end_effector_frame: &lt;TODO&gt;\n    base_frame: base\n\ngravity_compensation:\n    ros__parameters:\n    joints:\n        &lt;TODO&gt;\n\n    end_effector_frame: &lt;TODO&gt;\n    base_frame: base\n\n    task:\n        k_pos_x: 0.0\n        k_pos_y: 0.0\n        k_pos_z: 0.0\n        k_rot_x: 30.0\n        k_rot_y: 30.0\n        k_rot_z: 30.0\n\n    nullspace: \n        stiffness: 0.0\n\n    use_friction: true\n    use_coriolis_compensation: true\n    use_local_jacobian: true\n\njoint_impedance_controller:\n    ros__parameters:\n    joints:\n        &lt;TODO&gt;\n\n    end_effector_frame: &lt;TODO&gt;\n    base_frame: base\n\n    task:\n        k_pos_x: 0.0\n        k_pos_y: 0.0\n        k_pos_z: 0.0\n        k_rot_x: 0.0\n        k_rot_y: 0.0\n        k_rot_z: 0.0\n\n    max_delta_tau: 0.5\n\n    nullspace: \n        stiffness: 5.0\n        projector_type: none  # So we are directly controlling the joints!\n        damping: 0.5\n        max_tau: 5.0\n        regularization: 1.0e-06\n        weights:\n        &lt;TODO&gt;\n\n    use_friction: true\n    use_coriolis_compensation: true\n    use_local_jacobian: true\n    limit_error: true\n    limit_torques: true\n\n\ncartesian_impedance_controller:\n    ros__parameters:\n    joints:\n        - &lt;TODO&gt;\n\n    end_effector_frame: &lt;TODO&gt;\n    base_frame: &lt;TODO&gt;\n\n    task:\n        k_pos_x: 400.0\n        k_pos_y: 400.0\n        k_pos_z: 400.0\n        k_rot_x: 30.0\n        k_rot_y: 30.0\n        k_rot_z: 30.0\n\n    nullspace: \n        stiffness: 2.0\n\n    use_friction: false\n    use_coriolis_compensation: true\n    use_local_jacobian: true\n</code></pre> </li> <li> <p>Finally add them to your launch file.      You will need to use the controller_manager spawner to start the controllers at launch.     Usually, in the launch file you will find other controllers/broadcasters that are being launched.     Just duplicate the nodes and pass the correct names to activate the controllers.     Check out FR3 launch file for inspiration.</p> How to add the controllers to the launch file <p>Add the following nodes to the launch description:</p> <pre><code>...\nNode(\n    package=\"controller_manager\",\n    executable=\"spawner\",\n    arguments=[\"cartesian_impedance_controller\", \"--inactive\"],\n    output=\"screen\",\n),\nNode(\n    package=\"controller_manager\",\n    executable=\"spawner\",\n    arguments=[\"joint_impedance_controller\", \"--inactive\"],\n    output=\"screen\",\n),\nNode(\n    package=\"controller_manager\",\n    executable=\"spawner\",\n    arguments=[\"gravity_compensation\", \"--inactive\"],\n    output=\"screen\",\n),\nNode(\n    package=\"controller_manager\",\n    executable=\"spawner\",\n    arguments=[\"pose_broadcaster\"],\n    output=\"screen\",\n),\n...\n</code></pre> </li> <li> <p>After launching your robot you should see that new controller are being loaded. If you get stuck somewhere in the process feel free to open an issue.</p> </li> <li> <p>Finally, to use the robots in CRISP_PY, add a configuration file for the new robot and Gymnasium environments that use it.</p> New robot config example <p>my_new_robot/robot_config.py<pre><code>from crisp_py.robot_config import RobotConfig\n\n@dataclass\nclass MyNewRobotConfig(RobotConfig):\n\n    joint_names: list = field(\n        default_factory=lambda: [\n            \"joint1\",\n            \"joint2\",\n            \"joint3\",\n            ...\n        ]\n    )\n    home_config: list = field(\n        default_factory=lambda: [\n            np.pi,\n            0.0,\n            0.0,\n            ...,\n        ]\n    )\n    base_frame: str = \"base\"\n    target_frame: str = \"target_frame\"\n</code></pre> You can now use this config for your robot: your_test_script.py<pre><code>from crisp_py.robot import Robot\nfrom my_new_robot.robot_config import MyNewRobotConfig\n\nmy_new_robot_config = MyNewRobotConfig()\nmy_new_robot = Robot(config=my_new_robot_config, namespace=...)\n\nmy_new_robot.home()\n...\n</code></pre> In a similar manner, you can add this config to an Gymnasium environment to create a Gymnasium env with this config!</p> </li> <li> <p>Voila, you are good to go!</p> </li> </ol>"}]}